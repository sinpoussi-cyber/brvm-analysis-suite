# ==============================================================================
# MODULE: FUNDAMENTAL ANALYZER V16.0 - GEMINI 1.5 FLASH LATEST (11 CL√âS)
# ==============================================================================

import requests
from bs4 import BeautifulSoup
import time
import re
import os
from datetime import datetime
import logging
import unicodedata
import urllib3
import base64
from collections import defaultdict
from seleniumwire import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException, WebDriverException
import psycopg2

from api_key_manager import APIKeyManager

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')

# --- Configuration & Secrets ---
DB_NAME = os.environ.get('DB_NAME')
DB_USER = os.environ.get('DB_USER')
DB_PASSWORD = os.environ.get('DB_PASSWORD')
DB_HOST = os.environ.get('DB_HOST')
DB_PORT = os.environ.get('DB_PORT')

# ‚úÖ CONFIGURATION GEMINI (MOD√àLE CORRECT)
GEMINI_MODEL = os.environ.get("GEMINI_MODEL", "gemini-1.5-flash-latest")


class BRVMAnalyzer:
    def __init__(self):
        self.societes_mapping = {
            'NTLC': {'nom_rapport': 'NESTLE CI', 'alternatives': ['nestle ci', 'nestle']},
            'PALC': {'nom_rapport': 'PALM CI', 'alternatives': ['palm ci', 'palmci']},
            'UNLC': {'nom_rapport': 'UNILEVER CI', 'alternatives': ['unilever ci', 'unilever']},
            'SLBC': {'nom_rapport': 'SOLIBRA', 'alternatives': ['solibra ci', 'solibra']},
            'SICC': {'nom_rapport': 'SICOR', 'alternatives': ['sicor ci', 'sicor']},
            'SPHC': {'nom_rapport': 'SAPH', 'alternatives': ['saph ci', 'saph']},
            'SCRC': {'nom_rapport': 'SUCRIVOIRE', 'alternatives': ['sucrivoire', 'sucre']},
            'STBC': {'nom_rapport': 'SITAB', 'alternatives': ['sitab ci', 'sitab']},
            'SGBC': {'nom_rapport': 'SOCIETE GENERALE', 'alternatives': ['sgci', 'societe generale ci']},
            'BICC': {'nom_rapport': 'BICI', 'alternatives': ['bici ci', 'bici cote']},
            'NSBC': {'nom_rapport': 'NSIA BANQUE', 'alternatives': ['nsia ci', 'nsia banque ci']},
            'ECOC': {'nom_rapport': 'ECOBANK CI', 'alternatives': ['ecobank cote', 'eco ci']},
            'BOAC': {'nom_rapport': 'BANK OF AFRICA CI', 'alternatives': ['boa ci', 'boa cote']},
            'SIBC': {'nom_rapport': 'SIB', 'alternatives': ['sib ci', 'societe ivoirienne']},
            'BOABF': {'nom_rapport': 'BANK OF AFRICA BF', 'alternatives': ['boa bf', 'boa burkina']},
            'BOAS': {'nom_rapport': 'BANK OF AFRICA SN', 'alternatives': ['boa sn', 'boa senegal']},
            'BOAM': {'nom_rapport': 'BANK OF AFRICA MALI', 'alternatives': ['boa ml', 'boa mali']},
            'BOAN': {'nom_rapport': 'BANK OF AFRICA NIGER', 'alternatives': ['boa ng', 'boa niger']},
            'BOAB': {'nom_rapport': 'BANK OF AFRICA BENIN', 'alternatives': ['boa bn', 'boa benin']},
            'BICB': {'nom_rapport': 'BICI BENIN', 'alternatives': ['bici bn', 'bici benin']},
            'CBIBF': {'nom_rapport': 'CORIS BANK', 'alternatives': ['coris banking', 'coris bf']},
            'ETIT': {'nom_rapport': 'ECOBANK ETI', 'alternatives': ['eti', 'ecobank transnational']},
            'ORGT': {'nom_rapport': 'ORAGROUP', 'alternatives': ['oragroup togo', 'ora tg']},
            'SAFC': {'nom_rapport': 'SAFCA', 'alternatives': ['safca ci', 'saf ci']},
            'SOGC': {'nom_rapport': 'SOGB', 'alternatives': ['sogb ci', 'societe generale burkina']},
            'SNTS': {'nom_rapport': 'SONATEL', 'alternatives': ['sonatel sn', 'orange senegal']},
            'ORAC': {'nom_rapport': 'ORANGE CI', 'alternatives': ['orange cote', 'oci']},
            'ONTBF': {'nom_rapport': 'ONATEL', 'alternatives': ['onatel bf', 'onatel burkina']},
            'TTLC': {'nom_rapport': 'TOTAL CI', 'alternatives': ['totalenergies ci', 'total cote']},
            'TTLS': {'nom_rapport': 'TOTAL SN', 'alternatives': ['totalenergies sn', 'total senegal']},
            'SHEC': {'nom_rapport': 'VIVO ENERGY', 'alternatives': ['shell ci', 'vivo ci']},
            'CIEC': {'nom_rapport': 'CIE', 'alternatives': ['cie ci', 'compagnie ivoirienne']},
            'CFAC': {'nom_rapport': 'CFAO MOTORS', 'alternatives': ['cfao ci', 'cfao']},
            'PRSC': {'nom_rapport': 'TRACTAFRIC', 'alternatives': ['tractafric motors', 'tractafric ci']},
            'SDSC': {'nom_rapport': 'BOLLORE', 'alternatives': ['africa global logistics', 'sdv ci']},
            'ABJC': {'nom_rapport': 'SERVAIR', 'alternatives': ['servair abidjan', 'servair ci']},
            'BNBC': {'nom_rapport': 'BERNABE', 'alternatives': ['bernabe ci']},
            'NEIC': {'nom_rapport': 'NEI-CEDA', 'alternatives': ['nei ceda', 'neiceda']},
            'UNXC': {'nom_rapport': 'UNIWAX', 'alternatives': ['uniwax ci']},
            'LNBB': {'nom_rapport': 'LOTERIE BENIN', 'alternatives': ['loterie nationale benin']},
            'CABC': {'nom_rapport': 'SICABLE', 'alternatives': ['sicable ci']},
            'FTSC': {'nom_rapport': 'FILTISAC', 'alternatives': ['filtisac ci']},
            'SDCC': {'nom_rapport': 'SODE', 'alternatives': ['sode ci']},
            'SEMC': {'nom_rapport': 'EVIOSYS', 'alternatives': ['crown siem', 'eviosys packaging']},
            'SIVC': {'nom_rapport': 'AIR LIQUIDE', 'alternatives': ['air liquide ci']},
            'STAC': {'nom_rapport': 'SETAO', 'alternatives': ['setao ci']},
            'SMBC': {'nom_rapport': 'SMB', 'alternatives': ['smb ci', 'societe miniere']}
        }
        self.driver = None
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})
        self.analysis_memory = set()
        self.company_ids = {}
        self.newly_analyzed_reports = []
        
        self.api_manager = APIKeyManager('fundamental_analyzer')

    def connect_to_db(self):
        """Connexion √† PostgreSQL (Supabase)"""
        try:
            conn = psycopg2.connect(
                dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, 
                host=DB_HOST, port=DB_PORT, connect_timeout=10
            )
            return conn
        except Exception as e:
            logging.error(f"‚ùå Erreur connexion DB: {e}")
            return None

    def _load_analysis_memory_from_db(self):
        """Charge la m√©moire depuis PostgreSQL"""
        logging.info("üìÇ Chargement m√©moire depuis PostgreSQL...")
        conn = self.connect_to_db()
        if not conn: 
            return
        
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT report_url FROM fundamental_analysis;")
                urls = cur.fetchall()
                self.analysis_memory = {row[0] for row in urls}
            
            logging.info(f"   ‚úÖ {len(self.analysis_memory)} analyse(s) charg√©e(s)")
                    
        except Exception as e:
            logging.error(f"‚ùå Erreur chargement m√©moire: {e}")
            self.analysis_memory = set()
        finally:
            if conn: 
                conn.close()

    def _save_to_db(self, company_id, report, summary):
        """Sauvegarde dans PostgreSQL"""
        conn = self.connect_to_db()
        if not conn: 
            return False
        
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO fundamental_analysis (company_id, report_url, report_title, report_date, analysis_summary)
                    VALUES (%s, %s, %s, %s, %s) 
                    ON CONFLICT (report_url) DO UPDATE SET
                        analysis_summary = EXCLUDED.analysis_summary,
                        updated_at = CURRENT_TIMESTAMP
                    RETURNING id;
                """, (company_id, report['url'], report['titre'], report['date'], summary))
                
                inserted_id = cur.fetchone()[0]
                conn.commit()
            
            self.analysis_memory.add(report['url'])
            logging.info(f"    ‚úÖ Sauvegard√© (ID: {inserted_id})")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå Erreur sauvegarde: {e}")
            conn.rollback()
            return False
        finally:
            if conn: 
                conn.close()

    def setup_selenium(self):
        """Configuration Selenium"""
        try:
            logging.info("üåê Configuration Selenium...")
            
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-software-rasterizer')
            chrome_options.add_argument('user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36')
            
            seleniumwire_options = {
                'disable_encoding': True,
                'suppress_connection_errors': True,
                'connection_timeout': 30
            }
            
            self.driver = webdriver.Chrome(
                options=chrome_options,
                seleniumwire_options=seleniumwire_options
            )
            self.driver.set_page_load_timeout(30)
            self.driver.implicitly_wait(10)
            
            logging.info("   ‚úÖ Selenium configur√©")
            return True
        
        except Exception as e:
            logging.error(f"‚ùå Erreur Selenium: {e}")
            self.driver = None
            return False

    def _normalize_text(self, text):
        """Normalise le texte"""
        if not text:
            return ""
        
        text = ''.join(c for c in unicodedata.normalize('NFD', text) 
                       if unicodedata.category(c) != 'Mn')
        text = ' '.join(text.lower().split())
        
        return text

    def _find_all_reports(self):
        """Trouve tous les rapports financiers"""
        all_reports = defaultdict(list)
        
        try:
            url = "https://www.brvm.org/fr/capitalisation-marche"
            logging.info(f"   üîç Acc√®s √† {url}")
            
            self.driver.get(url)
            time.sleep(3)
            
            company_links = []
            elements = self.driver.find_elements(By.TAG_NAME, 'a')
            for elem in elements:
                try:
                    href = elem.get_attribute('href')
                    if href and '/societe/' in href:
                        company_links.append(href)
                except:
                    continue
            
            company_links = list(set(company_links))
            logging.info(f"   üìä {len(company_links)} page(s) trouv√©e(s)")
            
            for idx, link in enumerate(company_links, 1):
                try:
                    logging.info(f"   üìÑ Page {idx}/{len(company_links)}")
                    self.driver.get(link)
                    time.sleep(2)
                    
                    report_elements = self.driver.find_elements(By.TAG_NAME, 'a')
                    
                    for elem in report_elements:
                        try:
                            href = elem.get_attribute('href')
                            text = elem.text.strip()
                            
                            if not href or not href.endswith('.pdf'):
                                continue
                            
                            if any(kw in text.lower() for kw in ['rapport', 'financier', 'annuel', 'semestriel']):
                                date_match = re.search(r'(20\d{2})', text)
                                report_date = datetime(int(date_match.group(1)), 12, 31).date() if date_match else datetime.now().date()
                                
                                for symbol, info in self.societes_mapping.items():
                                    nom = self._normalize_text(info['nom_rapport'])
                                    alts = [self._normalize_text(a) for a in info.get('alternatives', [])]
                                    text_norm = self._normalize_text(text)
                                    
                                    if nom in text_norm or any(a in text_norm for a in alts):
                                        all_reports[symbol].append({
                                            'url': href,
                                            'titre': text,
                                            'date': report_date
                                        })
                                        break
                        except:
                            continue
                            
                except TimeoutException:
                    logging.warning(f"   ‚è±Ô∏è  Timeout page {idx}")
                    continue
                except WebDriverException as e:
                    logging.warning(f"   ‚ö†Ô∏è  Erreur WebDriver page {idx}: {e}")
                    continue
                except Exception as e:
                    logging.warning(f"   ‚ö†Ô∏è  Erreur page {idx}: {e}")
                    continue
            
            logging.info(f"   ‚úÖ {sum(len(r) for r in all_reports.values())} rapport(s) trouv√©(s)")
            return all_reports
        
        except Exception as e:
            logging.error(f"‚ùå Erreur recherche: {e}")
            return {}

    def _analyze_pdf_with_gemini(self, company_id, symbol, report, attempt=1, max_attempts=3):
        """Analyse un PDF avec Gemini 1.5 Flash Latest (avec limite de tentatives)"""
        pdf_url = report['url']
        
        if pdf_url in self.analysis_memory:
            logging.info(f"    ‚è≠Ô∏è  D√©j√† analys√©")
            return None
        
        conn = self.connect_to_db()
        if conn:
            try:
                with conn.cursor() as cur:
                    cur.execute("SELECT id FROM fundamental_analysis WHERE report_url = %s;", (pdf_url,))
                    if cur.fetchone():
                        logging.info(f"    ‚è≠Ô∏è  D√©j√† en base")
                        self.analysis_memory.add(pdf_url)
                        return None
            finally:
                conn.close()
        
        if attempt == 1:
            logging.info(f"    üÜï NOUVEAU: {os.path.basename(pdf_url)}")
        else:
            logging.info(f"    üîÑ Tentative {attempt}/{max_attempts}")
        
        # T√©l√©charger le PDF
        try:
            pdf_response = self.session.get(pdf_url, timeout=45, verify=False)
            pdf_response.raise_for_status()
            pdf_data = base64.b64encode(pdf_response.content).decode('utf-8')
        except Exception as e:
            logging.error(f"    ‚ùå Erreur t√©l√©chargement PDF: {e}")
            return False
        
        prompt = """Tu es un analyste financier expert. Analyse ce rapport financier et fournis une synth√®se concise en fran√ßais.

Concentre-toi sur :
- **Chiffre d'Affaires** : Variation en % et valeur
- **R√©sultat Net** : √âvolution et facteurs
- **Dividendes** : Propos√©, pay√© ou perspectives
- **Performance Op√©rationnelle** : Rentabilit√©
- **Perspectives** : Points cl√©s

Si une info manque, mentionne-le clairement."""
        
        # Obtenir la cl√© API (avec rotation automatique)
        api_key = self.api_manager.get_api_key()
        if not api_key:
            logging.error(f"    ‚ùå Aucune cl√© Gemini disponible")
            return False
        
        # ‚úÖ API GEMINI 1.5 FLASH LATEST
        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={api_key}"
        
        request_body = {
            "contents": [{
                "parts": [
                    {"text": prompt},
                    {
                        "inline_data": {
                            "mime_type": "application/pdf",
                            "data": pdf_data
                        }
                    }
                ]
            }]
        }
        
        try:
            response = requests.post(api_url, json=request_body, timeout=120)
            
            # Enregistrer la requ√™te
            self.api_manager.record_request()
            
            if response.status_code == 200:
                response_json = response.json()
                
                if 'candidates' in response_json and len(response_json['candidates']) > 0:
                    candidate = response_json['candidates'][0]
                    if 'content' in candidate and 'parts' in candidate['content']:
                        analysis_text = candidate['content']['parts'][0]['text']
                        
                        if self._save_to_db(company_id, report, analysis_text):
                            self.newly_analyzed_reports.append(f"Rapport {symbol}:\n{analysis_text}\n")
                            logging.info(f"    ‚úÖ {symbol}: Analyse g√©n√©r√©e")
                            return True
                
                logging.warning(f"    ‚ö†Ô∏è  R√©ponse Gemini malform√©e")
                return False
            
            elif response.status_code == 429:
                # Rate limit - g√©rer et r√©essayer AVEC LIMITE
                logging.warning(f"    ‚ö†Ô∏è  Rate limit d√©tect√© pour {symbol} (tentative {attempt}/{max_attempts})")
                
                # Essayer de changer de cl√©
                can_retry = self.api_manager.handle_rate_limit_response()
                
                # R√©essayer SEULEMENT si < max_attempts ET qu'il y a une cl√© disponible
                if attempt < max_attempts and can_retry:
                    time.sleep(2)  # Petite pause
                    return self._analyze_pdf_with_gemini(company_id, symbol, report, attempt + 1, max_attempts)
                else:
                    logging.error(f"    ‚ùå {symbol}: √âchec apr√®s {attempt} tentatives - UTILISATION DU FALLBACK")
                    # Sauvegarder une analyse par d√©faut
                    fallback_text = f"Analyse automatique indisponible pour ce rapport. Rapport: {report['titre']}"
                    self._save_to_db(company_id, report, fallback_text)
                    return False
            
            else:
                logging.error(f"    ‚ùå Erreur {response.status_code}: {response.text[:200]}")
                return False
                
        except requests.exceptions.Timeout:
            logging.error(f"    ‚è±Ô∏è  Timeout API Gemini")
            return False
        except Exception as e:
            logging.error(f"    ‚ùå Exception: {e}")
            return False

    def run_and_get_results(self):
        """Fonction principale"""
        logging.info("="*80)
        logging.info("üìÑ √âTAPE 4: ANALYSE FONDAMENTALE (V16.0 - Gemini 1.5 Flash Latest)")
        logging.info(f"ü§ñ Mod√®le: {GEMINI_MODEL}")
        logging.info("="*80)
        
        conn = None
        try:
            stats = self.api_manager.get_statistics()
            logging.info(f"üìä Cl√©s Gemini: {stats['available']}/{stats['total']} disponible(s)")
            
            self._load_analysis_memory_from_db()
            
            if not self.setup_selenium():
                logging.error("‚ùå Impossible d'initialiser Selenium")
                return {}, []
            
            conn = self.connect_to_db()
            if not conn: 
                return {}, []
            
            with conn.cursor() as cur:
                cur.execute("SELECT symbol, id, name FROM companies")
                companies_from_db = cur.fetchall()
            conn.close()
            
            self.company_ids = {symbol: (id, name) for symbol, id, name in companies_from_db}
            
            logging.info(f"\nüîç Phase 1: Collecte rapports...")
            all_reports = self._find_all_reports()
            
            logging.info(f"\nü§ñ Phase 2: Analyse IA (Gemini 1.5 Flash avec limite 3 tentatives)...")
            
            total_analyzed = 0
            total_skipped = 0
            
            for symbol, (company_id, company_name) in self.company_ids.items():
                logging.info(f"\nüìä {symbol} - {company_name}")
                company_reports = all_reports.get(symbol, [])
                
                if not company_reports:
                    logging.info(f"   ‚è≠Ô∏è  Aucun rapport")
                    continue
                
                date_2024 = datetime(2024, 1, 1).date()
                recent = [r for r in company_reports if r['date'] >= date_2024]
                recent.sort(key=lambda x: x['date'], reverse=True)
                
                logging.info(f"   üìÇ {len(recent)} rapport(s) r√©cent(s)")
                
                already = [r for r in recent if r['url'] in self.analysis_memory]
                new = [r for r in recent if r['url'] not in self.analysis_memory]
                
                logging.info(f"   ‚úÖ D√©j√†: {len(already)} | üÜï Nouveaux: {len(new)}")
                
                for report in new:
                    result = self._analyze_pdf_with_gemini(company_id, symbol, report)
                    if result is True:
                        total_analyzed += 1
                    elif result is None:
                        total_skipped += 1
                
                total_skipped += len(already)
            
            final_stats = self.api_manager.get_statistics()
            
            logging.info("\n‚úÖ Traitement termin√©")
            logging.info(f"üìä Nouvelles analyses: {total_analyzed}")
            logging.info(f"üìä Rapports ignor√©s: {total_skipped}")
            logging.info(f"üìä Requ√™tes effectu√©es: {final_stats['used_by_module']}")
            
            conn = self.connect_to_db()
            if not conn: 
                return {}, []
            
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT c.symbol, fa.analysis_summary, c.name 
                    FROM fundamental_analysis fa 
                    JOIN companies c ON fa.company_id = c.id
                """)
                final_results = defaultdict(lambda: {'rapports_analyses': [], 'nom': ''})
                
                for symbol, summary, name in cur.fetchall():
                    final_results[symbol]['rapports_analyses'].append({'analyse_ia': summary})
                    final_results[symbol]['nom'] = name
            
            logging.info(f"üìä R√©sultats: {len(final_results)} soci√©t√©(s)")
            return (dict(final_results), self.newly_analyzed_reports)
        
        except Exception as e:
            logging.critical(f"‚ùå Erreur: {e}", exc_info=True)
            return {}, []
        
        finally:
            if self.driver:
                try:
                    self.driver.quit()
                except:
                    pass
            if conn and not conn.closed: 
                conn.close()


if __name__ == "__main__":
    analyzer = BRVMAnalyzer()
    analyzer.run_and_get_results()
