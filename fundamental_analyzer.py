# ==============================================================================
# MODULE: FUNDAMENTAL ANALYZER V9.1 - VERSION CORRIG√âE
# ==============================================================================
# CORRECTIONS:
# - Fix selenium-wire options (compatibilit√© v5.x)
# - Am√©lioration gestion erreurs Selenium
# - Timeout explicites pour toutes les requ√™tes
# ==============================================================================

import requests
from bs4 import BeautifulSoup
import time
import re
import os
from datetime import datetime
import logging
import unicodedata
import urllib3
import base64
from collections import defaultdict
from seleniumwire import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException, WebDriverException
import psycopg2

from api_key_manager import APIKeyManager

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')

# --- Configuration & Secrets ---
DB_NAME = os.environ.get('DB_NAME')
DB_USER = os.environ.get('DB_USER')
DB_PASSWORD = os.environ.get('DB_PASSWORD')
DB_HOST = os.environ.get('DB_HOST')
DB_PORT = os.environ.get('DB_PORT')

# ‚úÖ CONFIGURATION GEMINI
GEMINI_MODEL = "gemini-1.5-flash"
GEMINI_API_VERSION = "v1beta"

class BRVMAnalyzer:
    def __init__(self):
        self.societes_mapping = {
            'NTLC': {'nom_rapport': 'NESTLE CI', 'alternatives': ['nestle ci', 'nestle']},
            'PALC': {'nom_rapport': 'PALM CI', 'alternatives': ['palm ci', 'palmci']},
            'UNLC': {'nom_rapport': 'UNILEVER CI', 'alternatives': ['unilever ci', 'unilever']},
            'SLBC': {'nom_rapport': 'SOLIBRA', 'alternatives': ['solibra ci', 'solibra']},
            'SICC': {'nom_rapport': 'SICOR', 'alternatives': ['sicor ci', 'sicor']},
            'SPHC': {'nom_rapport': 'SAPH', 'alternatives': ['saph ci', 'saph']},
            'SCRC': {'nom_rapport': 'SUCRIVOIRE', 'alternatives': ['sucrivoire', 'sucre']},
            'STBC': {'nom_rapport': 'SITAB', 'alternatives': ['sitab ci', 'sitab']},
            'SGBC': {'nom_rapport': 'SOCIETE GENERALE', 'alternatives': ['sgci', 'societe generale ci']},
            'BICC': {'nom_rapport': 'BICI', 'alternatives': ['bici ci', 'bici cote']},
            'NSBC': {'nom_rapport': 'NSIA BANQUE', 'alternatives': ['nsia ci', 'nsia banque ci']},
            'ECOC': {'nom_rapport': 'ECOBANK CI', 'alternatives': ['ecobank cote', 'eco ci']},
            'BOAC': {'nom_rapport': 'BANK OF AFRICA CI', 'alternatives': ['boa ci', 'boa cote']},
            'SIBC': {'nom_rapport': 'SIB', 'alternatives': ['sib ci', 'societe ivoirienne']},
            'BOABF': {'nom_rapport': 'BANK OF AFRICA BF', 'alternatives': ['boa bf', 'boa burkina']},
            'BOAS': {'nom_rapport': 'BANK OF AFRICA SN', 'alternatives': ['boa sn', 'boa senegal']},
            'BOAM': {'nom_rapport': 'BANK OF AFRICA MALI', 'alternatives': ['boa ml', 'boa mali']},
            'BOAN': {'nom_rapport': 'BANK OF AFRICA NIGER', 'alternatives': ['boa ng', 'boa niger']},
            'BOAB': {'nom_rapport': 'BANK OF AFRICA BENIN', 'alternatives': ['boa bn', 'boa benin']},
            'BICB': {'nom_rapport': 'BICI BENIN', 'alternatives': ['bici bn', 'bici benin']},
            'CBIBF': {'nom_rapport': 'CORIS BANK', 'alternatives': ['coris banking', 'coris bf']},
            'ETIT': {'nom_rapport': 'ECOBANK ETI', 'alternatives': ['eti', 'ecobank transnational']},
            'ORGT': {'nom_rapport': 'ORAGROUP', 'alternatives': ['oragroup togo', 'ora tg']},
            'SAFC': {'nom_rapport': 'SAFCA', 'alternatives': ['safca ci', 'saf ci']},
            'SOGC': {'nom_rapport': 'SOGB', 'alternatives': ['sogb ci', 'societe generale burkina']},
            'SNTS': {'nom_rapport': 'SONATEL', 'alternatives': ['sonatel sn', 'orange senegal']},
            'ORAC': {'nom_rapport': 'ORANGE CI', 'alternatives': ['orange cote', 'oci']},
            'ONTBF': {'nom_rapport': 'ONATEL', 'alternatives': ['onatel bf', 'onatel burkina']},
            'TTLC': {'nom_rapport': 'TOTAL CI', 'alternatives': ['totalenergies ci', 'total cote']},
            'TTLS': {'nom_rapport': 'TOTAL SN', 'alternatives': ['totalenergies sn', 'total senegal']},
            'SHEC': {'nom_rapport': 'VIVO ENERGY', 'alternatives': ['shell ci', 'vivo ci']},
            'CIEC': {'nom_rapport': 'CIE', 'alternatives': ['cie ci', 'compagnie ivoirienne']},
            'CFAC': {'nom_rapport': 'CFAO MOTORS', 'alternatives': ['cfao ci', 'cfao']},
            'PRSC': {'nom_rapport': 'TRACTAFRIC', 'alternatives': ['tractafric motors', 'tractafric ci']},
            'SDSC': {'nom_rapport': 'BOLLORE', 'alternatives': ['africa global logistics', 'sdv ci']},
            'ABJC': {'nom_rapport': 'SERVAIR', 'alternatives': ['servair abidjan', 'servair ci']},
            'BNBC': {'nom_rapport': 'BERNABE', 'alternatives': ['bernabe ci']},
            'NEIC': {'nom_rapport': 'NEI-CEDA', 'alternatives': ['nei ceda', 'neiceda']},
            'UNXC': {'nom_rapport': 'UNIWAX', 'alternatives': ['uniwax ci']},
            'LNBB': {'nom_rapport': 'LOTERIE BENIN', 'alternatives': ['loterie nationale benin']},
            'CABC': {'nom_rapport': 'SICABLE', 'alternatives': ['sicable ci']},
            'FTSC': {'nom_rapport': 'FILTISAC', 'alternatives': ['filtisac ci']},
            'SDCC': {'nom_rapport': 'SODE', 'alternatives': ['sode ci']},
            'SEMC': {'nom_rapport': 'EVIOSYS', 'alternatives': ['crown siem', 'eviosys packaging']},
            'SIVC': {'nom_rapport': 'AIR LIQUIDE', 'alternatives': ['air liquide ci']},
            'STAC': {'nom_rapport': 'SETAO', 'alternatives': ['setao ci']},
            'SMBC': {'nom_rapport': 'SMB', 'alternatives': ['smb ci', 'societe miniere']}
        }
        self.driver = None
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})
        self.analysis_memory = set()
        self.company_ids = {}
        self.newly_analyzed_reports = []
        
        self.api_manager = APIKeyManager('fundamental_analyzer')
        self.current_api_key = None

    def connect_to_db(self):
        """Connexion √† PostgreSQL (Supabase)"""
        try:
            conn = psycopg2.connect(
                dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, 
                host=DB_HOST, port=DB_PORT, connect_timeout=10
            )
            return conn
        except Exception as e:
            logging.error(f"‚ùå Erreur connexion DB: {e}")
            return None

    def _load_analysis_memory_from_db(self):
        """Charge la m√©moire depuis PostgreSQL"""
        logging.info("üìÇ Chargement m√©moire depuis PostgreSQL...")
        conn = self.connect_to_db()
        if not conn: 
            return
        
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT report_url FROM fundamental_analysis;")
                urls = cur.fetchall()
                self.analysis_memory = {row[0] for row in urls}
            
            logging.info(f"   ‚úÖ {len(self.analysis_memory)} analyse(s) charg√©e(s)")
                    
        except Exception as e:
            logging.error(f"‚ùå Erreur chargement m√©moire: {e}")
            self.analysis_memory = set()
        finally:
            if conn: 
                conn.close()

    def _save_to_db(self, company_id, report, summary):
        """Sauvegarde dans PostgreSQL"""
        conn = self.connect_to_db()
        if not conn: 
            return False
        
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO fundamental_analysis (company_id, report_url, report_title, report_date, analysis_summary)
                    VALUES (%s, %s, %s, %s, %s) 
                    ON CONFLICT (report_url) DO UPDATE SET
                        analysis_summary = EXCLUDED.analysis_summary,
                        updated_at = CURRENT_TIMESTAMP
                    RETURNING id;
                """, (company_id, report['url'], report['titre'], report['date'], summary))
                
                inserted_id = cur.fetchone()[0]
                conn.commit()
            
            self.analysis_memory.add(report['url'])
            logging.info(f"    ‚úÖ Sauvegard√© (ID: {inserted_id})")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå Erreur sauvegarde: {e}")
            conn.rollback()
            return False
        finally:
            if conn: 
                conn.close()

    def setup_selenium(self):
        """Configuration Selenium - VERSION CORRIG√âE"""
        try:
            logging.info("üåê Configuration Selenium...")
            
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-software-rasterizer')
            chrome_options.add_argument('user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36')
            
            # ‚úÖ CORRECTION: Options selenium-wire compatibles v5.x
            seleniumwire_options = {
                'disable_encoding': True,  # D√©sactive compression
                'suppress_connection_errors': True,  # Ignore erreurs SSL
                'connection_timeout': 30  # Timeout connexion
            }
            
            self.driver = webdriver.Chrome(
                options=chrome_options,
                seleniumwire_options=seleniumwire_options
            )
            self.driver.set_page_load_timeout(30)
            self.driver.implicitly_wait(10)
            
            logging.info("   ‚úÖ Selenium configur√©")
            return True
        
        except Exception as e:
            logging.error(f"‚ùå Erreur Selenium: {e}")
            self.driver = None
            return False

    def _normalize_text(self, text):
        """Normalise le texte"""
        if not text:
            return ""
        
        text = ''.join(c for c in unicodedata.normalize('NFD', text) 
                       if unicodedata.category(c) != 'Mn')
        text = ' '.join(text.lower().split())
        
        return text

    def _find_all_reports(self):
        """Trouve tous les rapports financiers"""
        all_reports = defaultdict(list)
        
        try:
            url = "https://www.brvm.org/fr/capitalisation-marche"
            logging.info(f"   üîç Acc√®s √† {url}")
            
            self.driver.get(url)
            time.sleep(3)
            
            company_links = []
            elements = self.driver.find_elements(By.TAG_NAME, 'a')
            for elem in elements:
                try:
                    href = elem.get_attribute('href')
                    if href and '/societe/' in href:
                        company_links.append(href)
                except:
                    continue
            
            company_links = list(set(company_links))
            logging.info(f"   üìä {len(company_links)} page(s) trouv√©e(s)")
            
            for idx, link in enumerate(company_links, 1):
                try:
                    logging.info(f"   üìÑ Page {idx}/{len(company_links)}")
                    self.driver.get(link)
                    time.sleep(2)
                    
                    report_elements = self.driver.find_elements(By.TAG_NAME, 'a')
                    
                    for elem in report_elements:
                        try:
                            href = elem.get_attribute('href')
                            text = elem.text.strip()
                            
                            if not href or not href.endswith('.pdf'):
                                continue
                            
                            if any(kw in text.lower() for kw in ['rapport', 'financier', 'annuel', 'semestriel']):
                                date_match = re.search(r'(20\d{2})', text)
                                report_date = datetime(int(date_match.group(1)), 12, 31).date() if date_match else datetime.now().date()
                                
                                for symbol, info in self.societes_mapping.items():
                                    nom = self._normalize_text(info['nom_rapport'])
                                    alts = [self._normalize_text(a) for a in info.get('alternatives', [])]
                                    text_norm = self._normalize_text(text)
                                    
                                    if nom in text_norm or any(a in text_norm for a in alts):
                                        all_reports[symbol].append({
                                            'url': href,
                                            'titre': text,
                                            'date': report_date
                                        })
                                        break
                        except:
                            continue
                            
                except TimeoutException:
                    logging.warning(f"   ‚è±Ô∏è  Timeout page {idx}")
                    continue
                except WebDriverException as e:
                    logging.warning(f"   ‚ö†Ô∏è  Erreur WebDriver page {idx}: {e}")
                    continue
                except Exception as e:
                    logging.warning(f"   ‚ö†Ô∏è  Erreur page {idx}: {e}")
                    continue
            
            logging.info(f"   ‚úÖ {sum(len(r) for r in all_reports.values())} rapport(s) trouv√©(s)")
            return all_reports
        
        except Exception as e:
            logging.error(f"‚ùå Erreur recherche: {e}")
            return {}

    def _get_next_api_key(self):
        """Obtient la prochaine cl√© API disponible"""
        key_info = self.api_manager.get_next_key()
        if key_info:
            self.current_api_key = key_info
            return key_info['key']
        return None

    def _analyze_pdf_with_api(self, company_id, symbol, report):
        """Analyse un PDF avec l'API Gemini"""
        pdf_url = report['url']
        
        if pdf_url in self.analysis_memory:
            logging.info(f"    ‚è≠Ô∏è  D√©j√† analys√©")
            return None
        
        conn = self.connect_to_db()
        if conn:
            try:
                with conn.cursor() as cur:
                    cur.execute("SELECT id FROM fundamental_analysis WHERE report_url = %s;", (pdf_url,))
                    if cur.fetchone():
                        logging.info(f"    ‚è≠Ô∏è  D√©j√† en base")
                        self.analysis_memory.add(pdf_url)
                        return None
            finally:
                conn.close()
        
        logging.info(f"    üÜï NOUVEAU: {os.path.basename(pdf_url)}")
        
        try:
            pdf_response = self.session.get(pdf_url, timeout=45, verify=False)
            pdf_response.raise_for_status()
            pdf_data = base64.b64encode(pdf_response.content).decode('utf-8')
        except Exception as e:
            logging.error(f"    ‚ùå Erreur t√©l√©chargement PDF: {e}")
            return False
        
        prompt = """Tu es un analyste financier expert. Analyse ce rapport financier et fournis une synth√®se concise en fran√ßais.

Concentre-toi sur :
- **Chiffre d'Affaires** : Variation en % et valeur
- **R√©sultat Net** : √âvolution et facteurs
- **Dividendes** : Propos√©, pay√© ou perspectives
- **Performance Op√©rationnelle** : Rentabilit√©
- **Perspectives** : Points cl√©s

Si une info manque, mentionne-le clairement."""
        
        max_attempts = len(self.api_manager.get_available_keys())
        attempts = 0
        
        while attempts < max_attempts:
            api_key = self._get_next_api_key()
            
            if not api_key:
                logging.error("    ‚ùå Aucune cl√© API disponible")
                return False
            
            key_num = self.current_api_key['number']
            logging.info(f"    ü§ñ Tentative avec cl√© #{key_num}")
            
            self.api_manager.handle_rate_limit()
            
            api_url = f"https://generativelanguage.googleapis.com/{GEMINI_API_VERSION}/models/{GEMINI_MODEL}:generateContent"
            
            headers = {
                "Content-Type": "application/json",
                "x-goog-api-key": api_key
            }
            
            request_body = {
                "contents": [{
                    "parts": [
                        {"text": prompt}, 
                        {"inline_data": {"mime_type": "application/pdf", "data": pdf_data}}
                    ]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 2048,
                }
            }
            
            try:
                response = requests.post(api_url, headers=headers, json=request_body, timeout=120)
                
                if response.status_code == 200:
                    response_json = response.json()
                    
                    # ‚úÖ CORRECTION: V√©rification de la structure de r√©ponse
                    if 'candidates' in response_json and len(response_json['candidates']) > 0:
                        candidate = response_json['candidates'][0]
                        if 'content' in candidate and 'parts' in candidate['content']:
                            analysis_text = candidate['content']['parts'][0]['text']
                            
                            if "erreur" not in analysis_text.lower():
                                if self._save_to_db(company_id, report, analysis_text):
                                    self.newly_analyzed_reports.append(f"Rapport {symbol}:\n{analysis_text}\n")
                                    return True
                    
                    logging.warning(f"    ‚ö†Ô∏è  R√©ponse API malform√©e")
                    return False
                
                elif response.status_code == 429:
                    logging.warning(f"    ‚ö†Ô∏è  Quota √©puis√© pour cl√© #{key_num}")
                    self.api_manager.mark_key_exhausted(key_num)
                    self.api_manager.move_to_next_key()
                    attempts += 1
                    continue
                
                elif response.status_code == 404:
                    logging.error(f"    ‚ùå 404 avec cl√© #{key_num}")
                    self.api_manager.move_to_next_key()
                    attempts += 1
                    continue
                
                elif response.status_code == 403:
                    logging.error(f"    ‚ùå 403 avec cl√© #{key_num}")
                    self.api_manager.mark_key_exhausted(key_num)
                    self.api_manager.move_to_next_key()
                    attempts += 1
                    continue
                
                else:
                    logging.error(f"    ‚ùå Erreur {response.status_code}")
                    self.api_manager.move_to_next_key()
                    attempts += 1
                    continue
                    
            except requests.exceptions.Timeout:
                logging.error(f"    ‚è±Ô∏è  Timeout cl√© #{key_num}")
                self.api_manager.move_to_next_key()
                attempts += 1
                continue
            except Exception as e:
                logging.error(f"    ‚ùå Exception cl√© #{key_num}: {e}")
                self.api_manager.move_to_next_key()
                attempts += 1
                continue
        
        return False

    def run_and_get_results(self):
        """Fonction principale"""
        logging.info("="*80)
        logging.info("üìÑ √âTAPE 4: ANALYSE FONDAMENTALE (V9.1 - CORRIG√âE)")
        logging.info("="*80)
        
        conn = None
        try:
            stats = self.api_manager.get_statistics()
            logging.info(f"üìä Cl√©s disponibles: {stats['available']}/{stats['total']}")
            
            self._load_analysis_memory_from_db()
            
            if not self.setup_selenium():
                logging.error("‚ùå Impossible d'initialiser Selenium")
                return {}, []
            
            conn = self.connect_to_db()
            if not conn: 
                return {}, []
            
            with conn.cursor() as cur:
                cur.execute("SELECT symbol, id, name FROM companies")
                companies_from_db = cur.fetchall()
            conn.close()
            
            self.company_ids = {symbol: (id, name) for symbol, id, name in companies_from_db}
            
            logging.info(f"\nüîç Phase 1: Collecte rapports...")
            all_reports = self._find_all_reports()
            
            logging.info(f"\nü§ñ Phase 2: Analyse IA...")
            
            total_analyzed = 0
            total_skipped = 0
            
            for symbol, (company_id, company_name) in self.company_ids.items():
                logging.info(f"\nüìä {symbol} - {company_name}")
                company_reports = all_reports.get(symbol, [])
                
                if not company_reports:
                    logging.info(f"   ‚è≠Ô∏è  Aucun rapport")
                    continue
                
                date_2024 = datetime(2024, 1, 1).date()
                recent = [r for r in company_reports if r['date'] >= date_2024]
                recent.sort(key=lambda x: x['date'], reverse=True)
                
                logging.info(f"   üìÇ {len(recent)} rapport(s) r√©cent(s)")
                
                already = [r for r in recent if r['url'] in self.analysis_memory]
                new = [r for r in recent if r['url'] not in self.analysis_memory]
                
                logging.info(f"   ‚úÖ D√©j√†: {len(already)} | üÜï Nouveaux: {len(new)}")
                
                for report in new:
                    result = self._analyze_pdf_with_api(company_id, symbol, report)
                    if result is True:
                        total_analyzed += 1
                    elif result is None:
                        total_skipped += 1
                
                total_skipped += len(already)
            
            final_stats = self.api_manager.get_statistics()
            
            logging.info("\n‚úÖ Traitement termin√©")
            logging.info(f"üìä Nouvelles analyses: {total_analyzed}")
            logging.info(f"üìä Rapports ignor√©s: {total_skipped}")
            logging.info(f"üìä Cl√©s utilis√©es: {final_stats['used_by_module']}")
            logging.info(f"üìä Cl√©s √©puis√©es: {final_stats['exhausted']}")
            logging.info(f"üìä Cl√©s disponibles: {final_stats['available']}")
            
            conn = self.connect_to_db()
            if not conn: 
                return {}, []
            
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT c.symbol, fa.analysis_summary, c.name 
                    FROM fundamental_analysis fa 
                    JOIN companies c ON fa.company_id = c.id
                """)
                final_results = defaultdict(lambda: {'rapports_analyses': [], 'nom': ''})
                
                for symbol, summary, name in cur.fetchall():
                    final_results[symbol]['rapports_analyses'].append({'analyse_ia': summary})
                    final_results[symbol]['nom'] = name
            
            logging.info(f"üìä R√©sultats: {len(final_results)} soci√©t√©(s)")
            return (dict(final_results), self.newly_analyzed_reports)
        
        except Exception as e:
            logging.critical(f"‚ùå Erreur: {e}", exc_info=True)
            return {}, []
        
        finally:
            if self.driver:
                try:
                    self.driver.quit()
                except:
                    pass
            if conn and not conn.closed: 
                conn.close()

if __name__ == "__main__":
    analyzer = BRVMAnalyzer()
    analyzer.run_and_get_results()
